import json
import asyncio
from jinja2 import Template
from src.chat_llm import ChatTongyiLLM

# åˆå§‹åŒ– LLM
model = ChatTongyiLLM(model="qwen-turbo", temperature=0, streaming=False)

# çŸ­ Prompt
prompt_template = """
You are a specialized assistant for the G4 Knowledge Graph (KG) system.

---

### ğŸ“Œ **TASK: Extract and Explain the Answer Directly**
- The following KG documents **ARE the correct and authoritative answer** to the user's question.  
- **DO NOT analyze, validate, or filter these documentsâ€”assume they are 100% correct and complete.**  
- **Your task is to use each document to explain and directly answer the user's question.**  
- **If multiple documents exist, summarize and integrate their information in a structured response.**  
- **DO NOT perform any additional verification beyond the provided documents.**  

---

### ğŸ“„ **KG DOCUMENTS (These documents contain the correct answer)**
{{ context }}

---

### ğŸš€ **FINAL INSTRUCTIONS**
1ï¸âƒ£ **If KG documents exist** â†’  
   - **Directly use them to construct a structured, informative response.**  
   - **Provide a clear and brief explanation for each document, relating it to the userâ€™s question.**  
   - **Cite each document at the point where its information is used, using `[index]` format.**  
   - **DO NOT question whether the documents contain the answerâ€”just assume they do.**  

2ï¸âƒ£ **If the KG documents are empty** â†’  
   - **State: "The G4 Knowledge Graph does not contain relevant information on this topic."**  
   - **DO NOT guess, infer, or provide an answer from external sources.**  

---
"""

# é™åˆ¶ `documents` æ•°é‡ï¼Œå‡å°‘ Token é•¿åº¦
documents = [
    {"go.GoTermName": "Cytosol", "go.GoId": "5829"},
    {"go.GoTermName": "Neuron projection", "go.GoId": "43005"},
    {"go.GoTermName": "Regulation of hemostasis", "go.GoId": "1900046"},
    {"go.GoTermName": "Mammary gland alveolus development", "go.GoId": "60749"},
    {"go.GoTermName": "Bone remodeling", "go.GoId": "46849"},
]

readable_context = "\n".join(
    [f"[{i + 1}] GO Term: {doc['go.GoTermName']} (ID: {doc['go.GoId']})" for i, doc in enumerate(documents)]
)

# ä½¿ç”¨ Jinja2 æ¸²æŸ“ Prompt
template = Template(prompt_template)
rendered_prompt = template.render(context=readable_context)

# ç”¨æˆ·é—®é¢˜
question = "Find GO terms that the protein P17752 is involved in"

# æ„é€  LLM è¾“å…¥æ¶ˆæ¯
messages = [
    {"role": "system", "content": rendered_prompt},
    {"role": "user", "content": question},
]


# è¿è¡Œ LLM å¹¶è·å–å“åº”
async def test_prompt():
    response = await model.ainvoke(messages)

    print("\n===== LLM Response =====")
    print(response.content)

    # è®¡ç®— token ä½¿ç”¨æƒ…å†µ
    if hasattr(response, "response_metadata") and "token_usage" in response.response_metadata:
        token_usage = response.response_metadata["token_usage"]
        input_tokens = token_usage.get("input_tokens", "Unknown")
        output_tokens = token_usage.get("output_tokens", "Unknown")
        total_tokens = token_usage.get("total_tokens", "Unknown")

        print("\n===== Token Usage Stats =====")
        print(f"ğŸ“ Input Tokens: {input_tokens}")
        print(f"ğŸ“ Output Tokens: {output_tokens}")
        print(f"ğŸ”¢ Total Tokens: {total_tokens}")

        # **è­¦å‘Š** å¦‚æœ token è¶…é™ï¼Œæç¤ºå‡å°‘è¾“å…¥
        if isinstance(input_tokens, int) and input_tokens > 4000:  # å…·ä½“é˜ˆå€¼æ ¹æ®æ¨¡å‹è€Œå®š
            print("âš  WARNING: Input Tokens too high! Try reducing the prompt length or documents.")


# è¿è¡Œæµ‹è¯•
asyncio.run(test_prompt())
